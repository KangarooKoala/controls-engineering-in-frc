\section{Numerical integration methods}
\label{sec:numerical_integration_methods}

Most systems don't have linear dynamics and their differential equations can't
be solved analytically. Instead, we'll have to approximate their solutions with
numerical integration.

\subsection{Butcher tableaus}

Butcher tableaus are a more succinct representation for explicit and implicit
Runge-Kutta numerical integration methods. Here's the general structure for
explicit methods.
\begin{equation*}
  \renewcommand\arraystretch{1.2}
  \begin{array}{c|cccc}
    0 \\
    c_2    & a_{2,1} \\
    \vdots & \vdots & \ddots \\
    c_s    & a_{s,1} & \hdots & a_{s,s-1} \\
    \hline
           & b_1    & \hdots & \hdots    & b_s
  \end{array}
\end{equation*}

where $s$ is the number of stages in the method, the matrix $[a_{ij}]$ is the
Runge-Kutta matrix, $b_1, \ldots, b_s$ are the weights, and $c_1, \ldots, c_s$
are the nodes. The top-left quadrant contains the sums of the rows in the
top-right quadrant. Each column in the right half corresponds to a $\mat{k}$
coefficient from $\mat{k}_1$ to $\mat{k}_s$.

The family of solutions to $\dot{\mat{x}} = f(t, \mat{x})$ is given by
\begin{align*}
  \mat{k}_1 &= f(t_k, \mat{x}_k) \\
  \mat{k}_2 &= f(t_k + c_2 h, \mat{x}_k + h (a_{2,1} \mat{k}_1)) \\
  &\ \ \vdots \\
  \mat{k}_s &= f(t_k + c_s h, \mat{x}_k +
    h (a_{s,1} \mat{k}_1 + \ldots + a_{s,s-1} \mat{k}_{s-1})) \\
  \mat{x}_{k+1} &= \mat{x}_k + h \sum_{i=1}^s b_i \mat{k}_i
\end{align*}

where $h$ is the timestep duration.

\subsection{Forward Euler method}
\index{numerical integration!Forward Euler}

The simplest explicit Runge-Kutta integration method is forward Euler
integration. We don't recommend using it because it suffers from numerical
stability issues. We'll demonstrate how to translate its Butcher tableau into
equations that integrate $\dot{\mat{x}} = f(t, \mat{x})$ from $0$ to $h$.
\begin{multicols}{2}
  \begin{alignat*}{7}
    \mat{k}_1 &= f(t +
      && {\color{blue}0} h,
      && \mat{x}_k)
      && \\
    \mat{x}_{k+1} &=
      &&
      && \mat{x}_k + h (
      && {\color{deepgreen}1} \mat{k}_1)
  \end{alignat*}
  \columnbreak
  \begin{equation*}
    \renewcommand\arraystretch{1.2}
    \begin{array}{c|c}
      {\color{blue}0} \\
      \hline
      & {\color{deepgreen}1}
    \end{array}
  \end{equation*}
\end{multicols}

Remove zeroed out terms.
\begin{align*}
  \mat{k}_1 &= f(t, \mat{x}_k) \\
  \mat{x}_{k+1} &= \mat{x}_k + h \mat{k}_1
  \intertext{Simplify.}
  \mat{x}_{k+1} &= \mat{x}_k + h f(t, \mat{x}_k)
\end{align*}

In FRC, our differential equations are of the form
$\dot{\mat{x}} = f(\mat{x}, \mat{u})$ where $\mat{u}$ is held constant between
timesteps. Since it's time-invariant, we can ignore the time argument of the
integration method. This gives theorem \ref{thm:forward_euler}.
\begin{theorem}[Forward Euler integration]
  \label{thm:forward_euler}

  Given the differential equation $\dot{\mat{x}} = f(\mat{x}_k, \mat{u}_k)$,
  this method solves for $\mat{x}_{k+1}$ at $h$ seconds in the future.
  $\mat{u}$ is assumed to be held constant between timesteps.
  \begin{multicols}{2}
    \begin{equation*}
      \mat{x}_{k+1} = \mat{x}_k + h f(\mat{x}_k, \mat{u}_k)
    \end{equation*}
    \columnbreak
    \begin{equation*}
      \renewcommand\arraystretch{1.2}
      \begin{array}{c|c}
        0 \\
        \hline
        & 1
      \end{array}
    \end{equation*}
  \end{multicols}
\end{theorem}

\subsection{Runge-Kutta fourth-order method}
\index{numerical integration!Runge-Kutta fourth-order}

The most common method we'll cover is Runge-Kutta fourth-order (RK4). It's
simple and accurate for most systems we'll see in FRC. We'll demonstrate how to
translate its Butcher tableau into equations that integrate
$\dot{\mat{x}} = f(t, \mat{x})$ from $0$ to $h$.
\begin{multicols}{2}
  \begin{alignat*}{7}
    \mat{k}_1 &= f(t +
      && {\color{blue}0} h,
      && \mat{x}_k)
      &&
      &&
      &&
      && \\
    \mat{k}_2 &= f(t +
      && {\color{blue}\frac{1}{2}} h,
      && \mat{x}_k + h (
      && {\color{deeporange}\frac{1}{2}} \mat{k}_1))
      &&
      &&
      && \\
    \mat{k}_3 &= f(t +
      && {\color{blue}\frac{1}{2}} h,
      && \mat{x}_k + h (
      && {\color{deeporange}0} \mat{k}_1 +
      && {\color{deeporange}\frac{1}{2}} \mat{k}_2))
      &&
      && \\
    \mat{k}_4 &= f(t +
      && {\color{blue}1} h,
      && \mat{x}_k + h (
      && {\color{deeporange}0} \mat{k}_1 +
      && {\color{deeporange}0} \mat{k}_2 +
      && {\color{deeporange}1} \mat{k}_3))
      && \\
    \mat{x}_{k+1} &=
      &&
      && \mat{x}_k + h (
      && {\color{deepgreen}\frac{1}{6}} \mat{k}_1 +
      && {\color{deepgreen}\frac{1}{3}} \mat{k}_2 +
      && {\color{deepgreen}\frac{1}{3}} \mat{k}_3 +
      && {\color{deepgreen}\frac{1}{6}} \mat{k}_4)
  \end{alignat*}
  \columnbreak
  \begin{equation*}
    \renewcommand\arraystretch{1.2}
    \begin{array}{c|cccc}
      {\color{blue}0} \\
      {\color{blue}\frac{1}{2}} & {\color{deeporange}\frac{1}{2}} \\
      {\color{blue}\frac{1}{2}} & {\color{deeporange}0}           & {\color{deeporange}\frac{1}{2}} \\
      {\color{blue}1}           & {\color{deeporange}0}           & {\color{deeporange}0}           & {\color{deeporange}1} \\
      \hline
                                & {\color{deepgreen}\frac{1}{6}}  & {\color{deepgreen}\frac{1}{3}}  & {\color{deepgreen}\frac{1}{3}} & {\color{deepgreen}\frac{1}{6}}
    \end{array}
  \end{equation*}
\end{multicols}

Remove zeroed out terms.
\begin{align*}
  \mat{k}_1 &= f(t, \mat{x}_k) \\
  \mat{k}_2 &= f(t + \frac{1}{2} h, \mat{x}_k + h \frac{1}{2} \mat{k}_1) \\
  \mat{k}_3 &= f(t + \frac{1}{2} h, \mat{x}_k + h \frac{1}{2} \mat{k}_2) \\
  \mat{k}_4 &= f(t + h, \mat{x}_k + h \mat{k}_3) \\
  \mat{x}_{k+1} &= \mat{x}_k + h \left(
    \frac{1}{6} \mat{k}_1 +
    \frac{1}{3} \mat{k}_2 +
    \frac{1}{3} \mat{k}_3 +
    \frac{1}{6} \mat{k}_4\right)
  \intertext{$\frac{1}{6}$ is usually factored out of the last equation to
    reduce the number of floating point operations.}
  \mat{x}_{k+1} &= \mat{x}_k + h \frac{1}{6} (
    \mat{k}_1 + 2\mat{k}_2 + 2\mat{k}_3 + \mat{k}_4)
\end{align*}

In FRC, our differential equations are of the form
$\dot{\mat{x}} = f(\mat{x}, \mat{u})$ where $\mat{u}$ is held constant between
timesteps. Since it's time-invariant, we can ignore the time argument of the
integration method. This gives theorem \ref{thm:rk4}.
\begin{theorem}[Runge-Kutta fourth-order integration]
  \label{thm:rk4}

  Given the differential equation $\dot{\mat{x}} = f(\mat{x}_k, \mat{u}_k)$,
  this method solves for $\mat{x}_{k+1}$ at $h$ seconds in the future.
  $\mat{u}$ is assumed to be held constant between timesteps.
  \begin{multicols}{2}
    \begin{align*}
      \mat{k}_1 &= f(\mat{x}_k, \mat{u}_k) \\
      \mat{k}_2 &= f(\mat{x}_k + h \frac{1}{2}\mat{k}_1, \mat{u}_k) \\
      \mat{k}_3 &= f(\mat{x}_k + h \frac{1}{2}\mat{k}_2, \mat{u}_k) \\
      \mat{k}_4 &= f(\mat{x}_k + h \mat{k}_3, \mat{u}_k) \\
      \mat{x}_{k+1} &= \mat{x}_k + h \frac{1}{6} (\mat{k}_1 + 2\mat{k}_2 +
        2\mat{k}_3 + \mat{k}_4)
    \end{align*}
    \columnbreak
    \begin{equation*}
      \renewcommand\arraystretch{1.2}
      \begin{array}{c|cccc}
        0 \\
        \frac{1}{2} & \frac{1}{2} \\
        \frac{1}{2} & 0 & \frac{1}{2} \\
        1 & 0 & 0 & 1 \\
        \hline
        & \frac{1}{6} & \frac{1}{3} & \frac{1}{3} & \frac{1}{6}
      \end{array}
    \end{equation*}
  \end{multicols}
\end{theorem}

Here's a reference implementation.
\begin{coderemote}{cpp}{snippets/RK4.cpp}
  \caption{RK4 implementation in C++}
\end{coderemote}

Other methods of Runge-Kutta integration exist with various properties
\cite{bib:wiki_rk4}, but the one presented here is popular for its high accuracy
relative to the amount of floating point operations (FLOPs) it requires.

\subsection{Dormand-Prince method}
\index{numerical integration!Dormand-Prince}

Dormand-Prince (RKDP) is a fourth-order method with fifth-order error checking.
It uses an adaptive stepsize to enforce an upper bound on the integration error.
\begin{theorem}[Dormand-Prince integration]
  \label{thm:rkdp}

  Given the differential equation $\dot{\mat{x}} = f(\mat{x}_k, \mat{u}_k)$,
  this method solves for $\mat{x}_{k+1}$ at $h$ seconds in the future.
  $\mat{u}$ is assumed to be held constant between timesteps. It has the
  following Butcher tableau.
  \begin{equation*}
    \renewcommand\arraystretch{1.2}
    \begin{array}{c|ccccccc}
      0 \\
      \frac{1}{5} & \frac{1}{5} \\
      \frac{3}{10} & \frac{3}{40} & \frac{9}{40} \\
      \frac{4}{5} & \frac{44}{45} & -\frac{56}{15} & \frac{32}{9} \\
      \frac{8}{9} & \frac{19372}{6561} & -\frac{25360}{2187} &
        \frac{64448}{6561} & -\frac{212}{729} \\
      1 & \frac{9017}{3168} & -\frac{355}{33} & \frac{46732}{5247} &
        \frac{49}{176} & -\frac{5103}{18656} \\
      1 & \frac{35}{384} & 0 & \frac{500}{1113} & \frac{125}{192} &
        -\frac{2187}{6784} & \frac{11}{84} \\
      \hline
      & \frac{35}{384} & 0 & \frac{500}{1113} & \frac{125}{192} &
        -\frac{2187}{6784} & \frac{11}{84} & 0 \\
      & \frac{5179}{57600} & 0 & \frac{7571}{16695} & \frac{393}{640} &
        -\frac{92097}{339200} & \frac{187}{2100} & \frac{1}{40}
    \end{array}
  \end{equation*}
  The first row of coefficients below the table divider gives the fifth-order
  accurate solution. The second row gives an alternative solution which,
  when subtracted from the first solution, gives the error estimate.
\end{theorem}

Here's a reference implementation.
\begin{coderemote}{cpp}{snippets/RKDP.cpp}
  \caption{RKDP implementation in C++}
\end{coderemote}
